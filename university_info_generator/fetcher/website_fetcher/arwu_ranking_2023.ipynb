{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import WebDriverException, NoSuchElementException, TimeoutException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pprint import pprint\n",
    "from typing import Dict, List\n",
    "\n",
    "import json\n",
    "import threading\n",
    "import os\n",
    "import requests\n",
    "\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "\n",
    "def store_cache(cache_path, cache: Dict[str, str]):\n",
    "    \"\"\"\n",
    "    Stores the provided cache dictionary into a JSON file at the specified path.\n",
    "\n",
    "    Args:\n",
    "        cache_path (str): The file path where the cache will be stored.\n",
    "        cache (dict): The cache data to store.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    with open(cache_path, \"w\", encoding=\"utf-8\") as cache_file:\n",
    "        for key, value in cache.items():\n",
    "            if isinstance(key, tuple):\n",
    "                key = str(key)\n",
    "\n",
    "            json_string = json.dumps({key: value}) + \"\\n\"  # Convert to JSON string with newline\n",
    "            cache_file.write(json_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "class ARWURankingCrawl:\n",
    "\n",
    "    base_url = \"https://www.shanghairanking.com\"\n",
    "    ranking_page_url = base_url + \"/rankings/arwu/2023\"\n",
    "\n",
    "    def __init__(self, total_num: int = 1000, num_per_page: int = 30):\n",
    "        self.total_num = total_num\n",
    "        self.num_per_page = num_per_page\n",
    "        self.num_page = total_num // num_per_page + 1\n",
    "        # System.setProperty(\"webdriver.chrome.driver\", \"C:\\\\driver\\\\chromedriver.exe\")\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        chrome_options.add_argument(\"--no-sandbox\")\n",
    "        self.driver = webdriver.Chrome(options=chrome_options)\n",
    "        self.ranking_info = {}\n",
    "        self.lock = threading.Lock()\n",
    "        self.df_path = \"/home/ivan/Uforse/university_crawl/university_info_generator/fetcher/website_fetcher/ranking_data/arwu_ranking_2023.csv\"\n",
    "\n",
    "    def get_first_page(self, url=ranking_page_url):\n",
    "        try:\n",
    "            self.driver.get(f\"{url}\")\n",
    "        except TimeoutException:\n",
    "            print(\"Page load timed out. Check your internet connection or website accessibility.\")\n",
    "            return None  # or handle as needed\n",
    "        except WebDriverException as e:\n",
    "            print(f\"An error occurred while trying to navigate: {e}\")\n",
    "            return None\n",
    "        # Full View\n",
    "        # self.driver.find_element(By.XPATH,'//*[@id=\"it-will-be-fixed-top\"]/div/div[1]/div/ul/li[2]/a').click()\n",
    "        return self.driver.page_source\n",
    "\n",
    "    def get_page_content(self):\n",
    "        try:\n",
    "            self.driver.find_element(By.CSS_SELECTOR, \"#content-box > ul > li.ant-pagination-next\").click()\n",
    "        except TimeoutException:\n",
    "            print(\"Page load timed out. Check your internet connection or website accessibility.\")\n",
    "            return None  # or handle as needed\n",
    "        except WebDriverException as e:\n",
    "            print(f\"An error occurred while trying to navigate: {e}\")\n",
    "            return None\n",
    "        return self.driver.page_source\n",
    "\n",
    "    def parse_page(self, page_content):\n",
    "        page_data = {}\n",
    "\n",
    "        soup = BeautifulSoup(page_content, \"html.parser\")\n",
    "        rows = soup.find_all(name=\"tr\")\n",
    "        for row in rows[-self.num_per_page :]:\n",
    "            # print(row)\n",
    "            row_bs = BeautifulSoup(str(row), \"html.parser\")\n",
    "            try:\n",
    "                rank = row_bs.find(name=\"div\", attrs={\"class\": \"ranking\"}).text.strip()\n",
    "                link = row_bs.find(name=\"a\")[\"href\"]\n",
    "                university_name = row_bs.find(name=\"span\", attrs={\"class\": \"univ-name\"}).text.strip()\n",
    "            except AttributeError:\n",
    "                print(\"Not enough info skipped\\n\" + str(row))\n",
    "                continue\n",
    "            page_data[university_name] = {\"rank\": rank, \"uni_link\": f\"{self.base_url}{link}\"}\n",
    "            # print(page_data[university_name])\n",
    "            self.ranking_info.update(page_data)\n",
    "        return page_data\n",
    "\n",
    "    def get_all_ranking(self):\n",
    "        with self.lock:\n",
    "            self.parse_page(self.get_first_page())\n",
    "        for _ in range(1, self.num_page + 1):\n",
    "            with self.lock:\n",
    "                self.parse_page(self.get_page_content())\n",
    "\n",
    "    def close(self):\n",
    "        if self.driver:\n",
    "            self.driver.quit()\n",
    "\n",
    "    def to_dataframe(self):\n",
    "        df = pd.DataFrame.from_dict(self.ranking_info, orient=\"index\").reset_index()\n",
    "        df.columns = [\"university_name\", \"rank\", \"arwu_uni_link\"]\n",
    "        return df\n",
    "\n",
    "    def to_csv(self):\n",
    "        df = self.to_dataframe()\n",
    "        file_path = \"/home/ivan/Uforse/university_crawl/university_info_generator/fetcher/website_fetcher/ranking_data/arwu_ranking_2023.csv\"\n",
    "        df.to_csv(file_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "    def filter_on_df(self, target_unis: pd.DataFrame):\n",
    "        if os.path.exists(self.df_path):\n",
    "            # File exists, load it into a DataFrame\n",
    "            arwu_data_frame = pd.read_csv(self.df_path)\n",
    "        else:\n",
    "            arwu_data_frame = self.to_dataframe()\n",
    "        # target_uni_canada = pd.read_csv(path_to_csv)\n",
    "        arwu_data_frame[\"university_name_lower\"] = arwu_data_frame[\"university_name\"].str.lower()\n",
    "        target_unis[\"university_name_lower\"] = target_unis[\"university_name\"].str.lower()\n",
    "        column_name = [\"canada_id\", \"arwu_name\", \"canada_name\", \"arwu_rank\", \"arwu_link\"]\n",
    "        matched_df = pd.DataFrame(columns=column_name)\n",
    "        for _, arwu_row in arwu_data_frame.iterrows():\n",
    "            arwu_name = arwu_row[\"university_name_lower\"]\n",
    "\n",
    "            # Check each university in the Canadian DataFrame for a substring match\n",
    "            for _, canada_row in target_unis.iterrows():\n",
    "                canada_name = canada_row[\"university_name_lower\"]\n",
    "                # Check if one name is a substring of the other\n",
    "                if arwu_name in canada_name or canada_name in arwu_name:\n",
    "                    # Add the match to the DataFrame\n",
    "                    matched_df = pd.concat(\n",
    "                        [\n",
    "                            matched_df,\n",
    "                            pd.DataFrame(\n",
    "                                [\n",
    "                                    [\n",
    "                                        canada_row[\"id_\"],\n",
    "                                        arwu_row[\"university_name\"],\n",
    "                                        canada_row[\"university_name\"],\n",
    "                                        arwu_row[\"rank\"],\n",
    "                                        arwu_row[\"arwu_uni_link\"],\n",
    "                                    ]\n",
    "                                ],\n",
    "                                columns=column_name,\n",
    "                            ),\n",
    "                        ],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "        matched_df.drop_duplicates(subset=[\"arwu_name\"], keep=\"first\", inplace=True)\n",
    "        return matched_df\n",
    "\n",
    "    def get_programs(self, url) -> List[str]:\n",
    "        def filter_target_table(tables):\n",
    "            target_tables = list(\n",
    "                filter(\n",
    "                    lambda table: \"undergraduate programs\" in table.select(\"table > thead > tr > th\")[0].string.lower(),\n",
    "                    tables,\n",
    "                )\n",
    "            )\n",
    "            if target_tables and len(target_tables) > 0:\n",
    "                return target_tables[0]\n",
    "            return None\n",
    "\n",
    "        result_lst = []\n",
    "        try:\n",
    "            # page = requests.get(f\"{url}\")\n",
    "            # soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "            self.driver.get(f\"{url}\")\n",
    "            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "            tables = soup.find_all(name=\"table\")\n",
    "            target_table = filter_target_table(tables)\n",
    "            if not target_table:\n",
    "                return []\n",
    "            table_soup = BeautifulSoup(str(target_table), \"html.parser\")\n",
    "            rows = table_soup.find(\n",
    "                name=\"tbody\",\n",
    "            ).find_all(\n",
    "                name=\"tr\",\n",
    "            )\n",
    "            for row in rows:\n",
    "                result_lst.append(row.string.strip())\n",
    "        except TimeoutException:\n",
    "            print(\"Page load timed out. Check your internet connection or website accessibility.\")\n",
    "        except WebDriverException as e:\n",
    "            print(f\"An error occurred while trying to navigate: {e}\")\n",
    "        if result_lst:\n",
    "            result_lst = list(set(result_lst))\n",
    "            result_lst.sort()\n",
    "        return result_lst\n",
    "\n",
    "    def get_all_programs(self, dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "        # matched_universities[[\"arwu_name\", \"arwu_link\"]]\n",
    "        column_name = [\"canada_id\", \"arwu_name\", \"canada_name\", \"programs\"]\n",
    "        result_df = pd.DataFrame(columns=column_name)\n",
    "        for _, row in dataframe.iterrows():\n",
    "            result_lst = self.get_programs(row[\"arwu_link\"])\n",
    "            if result_lst:\n",
    "                row_df = pd.DataFrame(\n",
    "                            [\n",
    "                                [\n",
    "                                    row[\"canada_id\"],\n",
    "                                    row[\"arwu_name\"],\n",
    "                                    row[\"canada_name\"],\n",
    "                                    f\"{result_lst}\",\n",
    "                                ]\n",
    "                            ],\n",
    "                            columns=column_name,\n",
    "                        )\n",
    "                result_df = pd.concat(\n",
    "                    [\n",
    "                        result_df,\n",
    "                        row_df,\n",
    "                    ],\n",
    "                    ignore_index=True,\n",
    "                )\n",
    "        return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     cra = ARWURankingCrawl()\n",
    "#     # pprint(cra.get_page_content(0))\n",
    "#     page = cra.get_all_ranking()\n",
    "#     pprint(page)\n",
    "#     try:\n",
    "#         file_path = \"/home/ivan/Uforse/university_crawl/university_info_generator/fetcher/website_fetcher/ranking_data/arwu_ranking_2023.jsonl\"\n",
    "#         store_cache(f\"{file_path}\", cra.ranking_info)\n",
    "#     except IOError as exc:\n",
    "#         raise IOError(f\"An error occurred while writing to the file: {file_path}\") from exc\n",
    "#     finally:\n",
    "#         cra.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cra = ARWURankingCrawl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_</th>\n",
       "      <th>university_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71</td>\n",
       "      <td>Algoma University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>University of Toronto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92</td>\n",
       "      <td>University of Calgary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Memorial University of Newfoundland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>University of Prince Edward Island</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_                      university_name\n",
       "0   71                    Algoma University\n",
       "1   49                University of Toronto\n",
       "2   92                University of Calgary\n",
       "3    1  Memorial University of Newfoundland\n",
       "4    2   University of Prince Edward Island"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# canada_data = pd.read_csv(\"/home/ivan/Uforse/university_crawl/university_info_generator/fetcher/website_fetcher/ranking_data/canada_dataset/all_universities_canada.csv\")\n",
    "# canada_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>canada_id</th>\n",
       "      <th>arwu_name</th>\n",
       "      <th>canada_name</th>\n",
       "      <th>arwu_rank</th>\n",
       "      <th>arwu_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>University of Toronto</td>\n",
       "      <td>University of Toronto</td>\n",
       "      <td>24</td>\n",
       "      <td>https://www.shanghairanking.com/institution/un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>New York University</td>\n",
       "      <td>York University</td>\n",
       "      <td>28</td>\n",
       "      <td>https://www.shanghairanking.com/institution/ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>Northwestern University</td>\n",
       "      <td>Western University</td>\n",
       "      <td>30</td>\n",
       "      <td>https://www.shanghairanking.com/institution/no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>University of British Columbia</td>\n",
       "      <td>The University of British Columbia</td>\n",
       "      <td>44</td>\n",
       "      <td>https://www.shanghairanking.com/institution/un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>King's College London</td>\n",
       "      <td>King's College</td>\n",
       "      <td>59</td>\n",
       "      <td>https://www.shanghairanking.com/institution/ki...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  canada_id                       arwu_name  \\\n",
       "0        49           University of Toronto   \n",
       "1        68             New York University   \n",
       "2        62         Northwestern University   \n",
       "3       100  University of British Columbia   \n",
       "4        65           King's College London   \n",
       "\n",
       "                          canada_name arwu_rank  \\\n",
       "0               University of Toronto        24   \n",
       "1                     York University        28   \n",
       "2                  Western University        30   \n",
       "3  The University of British Columbia        44   \n",
       "4                      King's College        59   \n",
       "\n",
       "                                           arwu_link  \n",
       "0  https://www.shanghairanking.com/institution/un...  \n",
       "1  https://www.shanghairanking.com/institution/ne...  \n",
       "2  https://www.shanghairanking.com/institution/no...  \n",
       "3  https://www.shanghairanking.com/institution/un...  \n",
       "4  https://www.shanghairanking.com/institution/ki...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# canada_data = pd.read_csv(\"/home/ivan/Uforse/university_crawl/university_info_generator/fetcher/website_fetcher/ranking_data/all_universities_canada.csv\")\n",
    "# canada_matched_universities = cra.filter_on_df(canada_data)\n",
    "# canada_matched_universities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# canada_matched_universities.to_csv(\"/home/ivan/Uforse/university_crawl/university_info_generator/fetcher/website_fetcher/ranking_data/canada_dataset/canada_uni_matched.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# canada_matched_universities.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# canada_result_df = cra.get_all_programs(canada_matched_universities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>canada_id</th>\n",
       "      <th>arwu_name</th>\n",
       "      <th>canada_name</th>\n",
       "      <th>programs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>University of Toronto</td>\n",
       "      <td>University of Toronto</td>\n",
       "      <td>['Aboriginal Studies', 'Accounting (B.Com)', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>Northwestern University</td>\n",
       "      <td>Western University</td>\n",
       "      <td>['African American Studies', 'African Studies'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>University of British Columbia</td>\n",
       "      <td>The University of British Columbia</td>\n",
       "      <td>['Accounting (Business)', 'Accounting (Vancouv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>McGill University</td>\n",
       "      <td>McGill University</td>\n",
       "      <td>['Accounting Economics', 'African Studies', 'A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>University of Alberta</td>\n",
       "      <td>University of Alberta</td>\n",
       "      <td>['Accounting', 'Active Living, Health and Well...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  canada_id                       arwu_name  \\\n",
       "0        49           University of Toronto   \n",
       "1        62         Northwestern University   \n",
       "2       100  University of British Columbia   \n",
       "3        19               McGill University   \n",
       "4        90           University of Alberta   \n",
       "\n",
       "                          canada_name  \\\n",
       "0               University of Toronto   \n",
       "1                  Western University   \n",
       "2  The University of British Columbia   \n",
       "3                   McGill University   \n",
       "4               University of Alberta   \n",
       "\n",
       "                                            programs  \n",
       "0  ['Aboriginal Studies', 'Accounting (B.Com)', '...  \n",
       "1  ['African American Studies', 'African Studies'...  \n",
       "2  ['Accounting (Business)', 'Accounting (Vancouv...  \n",
       "3  ['Accounting Economics', 'African Studies', 'A...  \n",
       "4  ['Accounting', 'Active Living, Health and Well...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# canada_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# canada_result_df.to_csv(\"/home/ivan/Uforse/university_crawl/university_info_generator/fetcher/website_fetcher/ranking_data/canada_dataset/canada_programs.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>canada_id</th>\n",
       "      <th>arwu_name</th>\n",
       "      <th>canada_name</th>\n",
       "      <th>programs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>University of Toronto</td>\n",
       "      <td>University of Toronto</td>\n",
       "      <td>[Aboriginal Studies, Accounting (B.Com), Actua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>Northwestern University</td>\n",
       "      <td>Western University</td>\n",
       "      <td>[African American Studies, African Studies, Af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>University of British Columbia</td>\n",
       "      <td>The University of British Columbia</td>\n",
       "      <td>[Accounting (Business), Accounting (Vancouver)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>McGill University</td>\n",
       "      <td>McGill University</td>\n",
       "      <td>[Accounting Economics, African Studies, Agricu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>University of Alberta</td>\n",
       "      <td>University of Alberta</td>\n",
       "      <td>[Accounting, Active Living, Health and Well-Be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  canada_id                       arwu_name  \\\n",
       "0        49           University of Toronto   \n",
       "1        62         Northwestern University   \n",
       "2       100  University of British Columbia   \n",
       "3        19               McGill University   \n",
       "4        90           University of Alberta   \n",
       "\n",
       "                          canada_name  \\\n",
       "0               University of Toronto   \n",
       "1                  Western University   \n",
       "2  The University of British Columbia   \n",
       "3                   McGill University   \n",
       "4               University of Alberta   \n",
       "\n",
       "                                            programs  \n",
       "0  [Aboriginal Studies, Accounting (B.Com), Actua...  \n",
       "1  [African American Studies, African Studies, Af...  \n",
       "2  [Accounting (Business), Accounting (Vancouver)...  \n",
       "3  [Accounting Economics, African Studies, Agricu...  \n",
       "4  [Accounting, Active Living, Health and Well-Be...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# canada_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # canada_result_df['programs'] = canada_result_df['programs'].apply(eval)\n",
    "# # canada_result_df.head()\n",
    "# # Explode the 'programs' column so each program gets its own row\n",
    "# df_exploded = canada_result_df.explode('programs')\n",
    "# df_exploded.to_csv(\"/home/ivan/Uforse/university_crawl/university_info_generator/fetcher/website_fetcher/ranking_data/canada_dataset/canada_programs_eval.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ivan/Uforse/university_crawl/university_info_generator/fetcher/website_fetcher/ranking_data/all_universities_usa.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1668888/2857926243.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0musa_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/ivan/Uforse/university_crawl/university_info_generator/fetcher/website_fetcher/ranking_data/all_universities_usa.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0musa_matched_universities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_on_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musa_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0musa_matched_universities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0musa_result_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_programs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musa_matched_universities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0musa_result_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/ivan/Uforse/university_crawl/university_info_generator/fetcher/website_fetcher/ranking_data/usa_programs.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ivan/Uforse/university_crawl/university_info_generator/fetcher/website_fetcher/ranking_data/all_universities_usa.csv'"
     ]
    }
   ],
   "source": [
    "usa_data = pd.read_csv(\"/home/ivan/Uforse/university_crawl/university_info_generator/fetcher/website_fetcher/ranking_data/all_universities_usa.csv\")\n",
    "usa_matched_universities = cra.filter_on_df(usa_data)\n",
    "usa_matched_universities.head()\n",
    "usa_result_df = cra.get_all_programs(usa_matched_universities)\n",
    "usa_result_df.to_csv(\"/home/ivan/Uforse/university_crawl/university_info_generator/fetcher/website_fetcher/ranking_data/usa_programs.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_matched_universities.to_csv(\"/home/ivan/Uforse/university_crawl/university_info_generator/fetcher/website_fetcher/ranking_data/usa_uni_matched.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_result_df['programs'] = usa_result_df['programs'].apply(eval)\n",
    "\n",
    "# Explode the 'programs' column so each program gets its own row\n",
    "df_exploded = usa_result_df.explode('programs')\n",
    "df_exploded.to_csv(\"/home/ivan/Uforse/university_crawl/university_info_generator/fetcher/website_fetcher/ranking_data/usa_programs_eval.csv\", encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
